
\section{Evaluation of Project}
Evaluation of the project consisted of multiple stages ranging from verification of the functional requirements through simple black box testing to evaluation of refined mesh quality using methods provided by Dittmer \cite{DittmerMeshQualityMet}. 

\subsection{Validation Against Functional Requirements}
In order to validate the system against many of the functional requirements the system only needs to be run on several basic models with different input configurations. Having run the system on a range of different models results clearly demonstrate the system's ability to evaluate the quality of meshes using multiple refinement processes based on the stresses induced by the user and their categorisation of edges within the model. 

\subsection{Validation Against Non Functional Requirements}
Validation of non functional requirements was made simple due to the limited number of them, this was partly a consequence of the system not being designed for a specific user base resulting in expectations regarding the system's design to improve usability and guide interaction. It was also not possible to define the general accuracy and performance of the system during the requirement elicitation phase since this could only be determined once the required research and trial on the finished system gave indication to both of these. \\

\noindent
In the case of quality for the system's design and documentation evidence is present, (see appendices B, F and G)  to indicate that this adheres to the requirements specified with the project submission containing detailed documentation in the form of a Deoxygen guide and use of object oriented and functional software design as seen within the codebase. General applicability of functionality has also been demonstrated through evaluation using a variety of both models and conditions when performing simulations.

\subsection{Unit Testing}
Holistic evaluation provided evidence of the overall system's effectiveness however without verification of individual components it would not have been possible to assert the accuracy of the results produced. Unit testing was also conducted from within Visual Studio using the NUnit framework and structured as a separate VS project. This guaranteed that the system was not able to interact with the tests and that testing was conducted through the class and function interfaces provided by the implemented solution. Tests were also grouped into classes with each test class corresponding approximately to one class within the system. Each test class then contains a number of test functions each of which performing the asserts necessary to deem its associated function as correct. This layout provided clear traceability from each item of function to its associated test making assessment of the test coverage much easier. Appendix B shows the visual studio test explorer containing the various tests. \\


\subsection{Software Quality and Management}
The quality of the design and implementation of the system reflects my experience not only as a computer science undergraduate but as a developer with one year industrial experience, although not directly effecting the execution of the program properties such as appropriate variable naming, loose coupling of classes, use of abstractions and descriptive error messages make the software easier to read and debug for any potential future developers. \\

\noindent
Visual Studio also enabled calculation of various software quality metrics for the code base automatically. This made selecting parts of the codebase for refactoring much easier when time was allocated for this. Upon completion of the project the average maintainability index \cite{VisualStudioMaintainIndex} across all modules was 75 with the lowest score for any high level module being 60 and the highest 92. According to the Microsoft Developer Network (MSDN) website code with an index of between 0 and 9 indicates low maintainability, 10 to 19 indicates moderately maintainable and 20 to 100 high maintainabilty. \\

\noindent
In order to ensure progress was responsibly backed up and new features easily managed a private Github repository was set up and all progress made to the project was pushed every couple of days. This proved invaluable on at least one occasion where a bug was accidentally introduced and despite efforts could not be removed manually. 


\subsection{Documentation}
The process of continuously writing descriptive documentation was important to the success of the project and was treated as an integral part to meeting the goals of the project development methodology which aimed to reduce the systems complexity and improve readability. Through the writing Doc comments corresponding to every function within the codebase it was possible to generate documentation files automatically through use of the tool Doxygen. This allows anyone with the solution to view descriptions of each of its functions either in the codebase or alternatively through the manual produced automatically by Doxygen, for example see appendix. \\ 

 

\subsection{Evaluation Of System For Model Simulations}
%To demonstrate the systems applicability to a variety of real engineering problems demanded the creation of several models resembling basic equivalents of real structures that are often analysed by FE methods.

%As a system designed to facilitate analysis of hybrid meshing techniques the ability to conduct detailed evaluation for a set of hybrids over multiple simulations demonstrates successful generality. \\

In order to perform reasonable evaluation of the different methods it was important to carefully design tests for the system which would fairly evaluate its ability to generate a range of hybrid methods capable of performing meshing. \\ 

\noindent
Firstly it was important to test the various methods individually for at least one model in order to verify that each of the methods individually performs as expected, this step does not produce particularly interesting results although is an key step in order to have trust in the results subsequently produced by the hybrids. When evaluating the hybrids the system also needed to be evaluated for several different FE models with varying simulation conditions. This demonstrates consistency in the results and de  the systems ability to work for a range of different model inputs. \\

\noindent
Since the system also builds hybrids from different weightings of the stress and heuristic refinement methods it was also important to ensure that when the systems performance could be partially attributed to the heuristic component the range of possible user inputs for the edge specifications was taken into account. \\  

\noindent
Three models were created in total for evaluation, with each of the models being a general simplification of some more complex model that could be expected within an industrial engineering setting. Each model has a manually constructed low fidelity mesh built using LISA's graphical user interface. The models also have a set of forces applied to them which are required so that stress is induced within the simulation. Constraints are also assigned to surfaces as described under section 2.1. \\ 


\noindent
\textbf{Different Quality Edge Specifications: } Deliberate variation of inputs for the heuristic component was also important for making a general assessment of the heuristic method, see 6.4 for heuristic edge specifications. Since the users specify the edges that determine the meshing focus they directly affect the final result of the process, it is therefore important to consider the results produced by the system for a variety of different potential users. The effects of good and bad edge specifications can be observed both in execution times for the simulations and in the system's ability to mesh accurately where required as seen in figure 14 and the mesh structure in appendix F. \\ 

\noindent
Since it was not possible to objectively compare the edge specifications for different models that were evaluated a basic criteria was developed so that comparisons could be drawn. For each model four sets of of edges were consequently constructed and given classifications of ``Best'', ``Good'', ``Ok'' and ``Poor'' With the following as general guidelines for defining each set: \\

\noindent
\textbf{Best: } Approximately five edges specified directly over or adjacent to those areas of known high stress within the model - input potentially generated by a user with a high degree of expertise in evaluating the specific type of structure. \\ 

\noindent
\textbf{Good: } Approximately three edges over or close to areas of high stress within the model - input potentially generated by a user with a high degree of general FE experience although potentially not specific to that type of structure. \\ 

\noindent
\textbf{Ok: } Three to five edges some near high stress and other not - representing a user with some experience but by no means an expert. \\ 

\noindent
\textbf{Poor: } Three to five edges none of which are close to areas of high stress - representing input as would be generated by an inexperienced user new to FE stress analysis. \\ 

\noindent
As someone who would identify as an inexperienced user determining the areas of high stress in advance was important in order to successfully develop rule sets which satisfied each of these categories for the different simulations. The system was therefore initially run for each model without a heuristic component in order to provide some indication of what edges could be used for each set. Having designed four edge sets for each of the three evaluation models data could then be collected on the performance of both the individual heuristic and the combined hybrid method for each of these methods based on different levels of user expertise. \\

\noindent
A clear drawback of not having the edge sets defined by an experienced FE engineer is a lack of a guarantee that the edge sets chosen by me accurately represent those similar to what would be specified by a typical user of the system. At best it can be asserted that the sets represent a range of deviations from the theoretical ideal for the edge specifications which it is reasonable to expect from users with varying degrees of skill. Consequently it is only possible to objectively judge each of the different sets on the basis of the results they produce. These results for the different specifications cannot be claimed to represent the output mesh of a user group.\\ 


\subsubsection{Metrics Selections}

\noindent
Due to the complex nature of finite element models there are a huge number of potential methods that can be calculated from the available stress data and mesh. selecting appropriate metrics by which to draw conclusions from the different models was in itself challenging. Below I have described the metrics I eventually selected along with a description of what they indicate and why this was important to conclude the systems ability to meet its objectives. \\ 

For subsequent evaluation of hybrids the following metrics are then 

\noindent
\textbf{Average Maximum Internal Corner Angle: } This metric was cited by Dittmer \cite{DittmerMeshQualityMet}as one of the most consistent indicators by which to evaluate the quality of a mesh with gradual deviation from the optimum indicating a degradation in quality and the meshing processes inability to maintain quality and consequently insure accuracy of subsequent results. \\ 

\noindent
\textbf{Execution Times: } Since it is important for all methods to run in a reasonable amount of time, measuring the increase in runtime with additional iterations provided a good indication of how costly each approach became and whether there were any points at which meshing became significantly more expensive. \\ 

\noindent
\textbf{Average Stress Revealed for Each Iteration: } In order to measure the different methods ability to reveal stress over time the average stress underneath an elements across the model was an effective metric. with increase in the average occurring as a result of more elements being placed on those areas of high stress and decrease occurring with creation of elements over areas of lower stress. Since this metric is a measurement of stress which is force over a given area stress is essentially a measure of pressure and as such the unit of measurement used is pascals. \\ 


\subsubsection{Evaluation of Bridge Structure}
The suspension bridge model consists of 196 elements of quad4 type and 212 nodes which can be considered coarse given the size of the structure. Four constraint points were specified at the base of each supporting column and strong forces of applied across the structure along the negative x axis. \\

The first step taken before evaluating the hybrids was to find

\noindent
The results in figure 14 below show the increase in time taken to complete execution and the number of elements generated having reached each iteration, the growth in both of these are linear which indicates that no individual method is doing significantly more meshing than another. This shows both the methods are closely balanced the importance of which is described in section 5.8. Looking at b it can also be seen that the quality of individual heuristics does not necessarily result in more meshing with it being possible to mesh more in undesirable areas given poor user input, a better edge specification  therefore does not simply have an advantage over a poorer one by being able to conduct more meshing. \\ 

\noindent
These tests indicate that subsequent evaluations for hybrid methods are conducted fairly with each weightings representing equatable in  the number of elements created and consequently the execution time. \\

% show angle and runtime

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{../Graphics/Graphs/SingleMethods/ExecutionTimes.png}
  \caption{Time taken to complete each iteration using the different methods}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.75\linewidth]{../Graphics/Graphs/SingleMethods/NumberOfElements.png}
  \caption{Increase in number of elements for each of the individual refinement methods}
  \label{fig:sub2}
\end{subfigure}
\label{fig:test}
  \caption{Execution time increase compared to the amount of information revealed for the different approaches}
 \end{figure}
 
\noindent
The maximum internal corner angles can be seen as improving fairly linearly over time although with a the greatest rate of improvement occurring during the first few iterations for each method before the average for the mesh approaches the optimum, which for elements of type quad4 is 90 degrees. This means in general the refinement methods reduce skew present within the model through the creation of new elements and the calculated stress retaining its accuracy. 

%This indicates that the refinement methods tend to reduce element skew within the mesh by effectively smoothing the mesh. This suggests that the results produced by the solver can be assumed to be at least if not more accurate after the mesh has been refined than before. This trend also extends to the other two evaluation models suggesting that the underlying subdivision process does not generate meshes that compromise the calculation of stress values for any input mesh.


\begin{figure}[H]
  \centerline{\includegraphics[width=110mm, scale=1]{../Graphics/Graphs/SingleMethods/AngleImprovements.png}}
  \caption{Approaching the ideal quad4 geometry for simulation data accuracy of 90 degrees using refinement with each of the different methods}
  \label{fig:sub1}
\end{figure}  

\noindent
%A key realisation having calculated the average maximum angles for the different methods was although Dittmers metrics helped to indicates that the results produced by the solver are accurate they do not actually demonstrate one refinement methods ability to mesh in more desirable areas than another while retaining a lower computational overhead through creation of fewer elements, an alternative metric was clearly needed in order to show this. A simple solution which proved highly effective was simply to calculate the average stress across all nodes. By calculating the average each method effectively achieved a high score for placing few elements directly over the high stress area while avoiding element creation over lower stress areas that would reduce the average.\\ 

\noindent
Graphing this for multiple iterations gave an accurate representation of each methods effectiveness with the average being reduced if a method poorly selects an area under which to refine and increased if meshing occurs exclusively in areas of concentrated stress. \\

\noindent
Evaluating each of the individual methods using this metric with various weightings produced the following results: \\ 

\colorbox{yellow}{Need to re run one of the sets to re produce the graph because I got the input settings wrong for it} \\ 

% graphs for improvement of different methods.
\noindent
Having completed analysis for each of the individual methods it was reasonable to run some hybrid strategies for each of the models, successful execution of the models produced results that indicate rapid overall improvement with regards to finding stress as can be seen below in figure 17. Rapid improvement can be seen during the first few iterations in figure 17a before achieving a plateau was intitially highly surprising to the extent that for a period it seemed like the results must be incorrect. Re execution of the model with varying configurations including reduced force and alternative constraints resulted in minimal difference however. Conducting additional research then revealed that this is not in fact an uncommon property of stress gradients within FE models as stress will trend towards infinity at points of serious weakness within a design when very high force is exerted, see appendix I (figure 34) and figure 17b \cite{StressConcerntration}.  \\

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{../Graphics/Graphs/AverageStressesBridge/AverageStressRevealedForIndividualMethodWeightings.png}
  \caption{Average stress revealed with different weightings for the individual methods as a component of a hybrid.}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1.1\linewidth]{../Graphics/Graphs/AverageStressesBridge/HybridResultsAveraged.png}
  \caption{Average stress revealed using multiple iterations of the different hybrid methods over time}
  \label{fig:sub2}
\end{subfigure}
\label{fig:test}
  \caption{Amount of stress revealed under mesh over multiple iterations}
 \end{figure}


\noindent
Looking at figure 16a above it is clear where there are weaknesses at predictable points the increasing speed at which meshing can be focused using heuristic refinement is significant, in particular during the first few iterations, see iteration 2 in figure 16a above. This suggests that the heuristics can on average perform better than a more general approach given a specific case. As expected however the extent to which this is true highly depends upon the users ability to correctly identify regions of interest in advance. Figure 16 below shows the bridge model undergoing relatively high stress at various points across the model but with exponential increase at specific points where structures join one another. \\ 

\noindent
Figure 16b above indicates some unpredictability in the hybrid results from combining multiple methods. For example hybrid (3, 2) shows poor performance until iteration three while the others including hybrids with less precedence given to the hybrid with additional fluctuations between all four methods during the final four iterations. After closer observation of the models within LISA it seems the most likely cause of this is overlapping of areas between the different methods to the affect that a heuristic method often reveals just some of a high stress area which when observed by the stress refinement method triggers much more detailed refinement at that particular location. 
The alternative to this is the stress refiner has to do a lot more meshing relatively around the general area by itself in order to find this location. This effect can also be observed for different corner and edge points in figure 17a and b below. \\

\noindent
This suggests that although heuristic refinement can potentially be unreliable if used individually, as a supplementary method to support stress based refinement it has potential to improve the overall speed when analysing an FE model. \\

\noindent
Having run the model with the hybrids the coloured stress gradients across each structure could be inspected as an engineer would, see figure 18 and appendices H, I and J below. LISA assigns colours to different ranges of stress based on the range of values within the model. It is therefore possible for green to potentially represent a degree of high stress in cases where high stress exists across the entire model and so this is the average, although in the majority of cases this will not be true with red areas representing those of highest stress followed by orange, yellow, green, light blue and eventually dark blue.  \\ 

%When designing the models it was therefore desirable apply forces such that there would be stress concentrations and resulting in clear gradients. \\ 

\noindent
Looking at the gradient meshes in figure 18 it can be seen that refinement has been successfully focused in those areas of high stress with meshing becoming increasingly focused on smaller and smaller areas covering the highest stress this affect can be seen after as seen clearly after 8 iterations in figure 18b below and also in appendix H. This is supported by the data shown above in figure 17 above with the dramatic increase in the average stress revealed per iteration and thus convergence of the meshing procedures on these areas. \\ 

\noindent
This effect is the desired result of applying mesh refinement as discussed in section 2 on the projects motivation and background.  

%say something about how actually you want a bit of distribution
%\noindent
%Comparing the amount of improvement performed by both the stress and heuristic refinement processes with varying weightings that in general heuristics performed better than stress refinement although interestingly more weighting did not necessarily correlate to better results as can be be seen with heuristic weighting of two doing a better job than weighting four in the final iteration. \\

%../Graphics/BridgeCrossLoadingStress/bridgeStressBasic.png
\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{../Graphics/BridgeCrossLoadingStress/Hybrid-best-3-2.png}
  \caption{Stress Revealed through the initial highly coarse bridge mesh without running any iterations for either method}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{../Graphics/BridgeCrossLoadingStress/BridgeCrossLoadingStress6-3-2.png}
  \caption{Stress revealed within model after just 4 iterations with a heuristic stress method weighting of 3-2, edge heuristics also considered good in this case}
  \label{fig:sub2}
\end{subfigure}
\label{fig:test}
  \caption{Execution time increase to the amount of information revealed for the different approaches}
 \end{figure}


%Results obtained from this model can be used for verification against a comparable system the meshes for both the paper mill and cylinder structures have been designed to closely resemble the input data originally used by Dolsak as input for training the ILP when generating the rule set, \cite{DolsakPaper91} although there is little numerical data on the results of simulation with these meshes. 
%Comparing the results for these models against those obtained by Dolsak provides a means of evaluating both the implementation of the ILP generated rules within system in addition to providing general models for which  the results obrained for the suspension bridge can be compared.
%suspension bridge goes beyond Dolsak models. 
%\cite{}
%\noindent
%The two additional models one being a section of a paper mill disk and another being half of cylinder were both based on designs specified within Dolsaks paper 
% \cite{SuspensionBridgeMeasurements}.

%independently of one other. This provided data on the performance of each approach making it easier to evaluate the results of hybrid executions later.
%evaluate both approaches before attempting to combine the two. Testing each method

%\noindent
%For stress refinement the varied parameter was the threshold used to determine whether elements were considered under high stress and should be further refined. The main consequence of varying this parameter was change in both the node count and the programs runtime as can be seen in Figure 14a. Despite time complexity for subdivision being $O(n^2)$ for all methods using a low threshold results in large values of n and consequently a rapid increase in both runtime and element count. \\


%\subsubsection{Evaluation Issues}
%A significant issue faced in attempting to demonstrate the effectiveness of the system was to provide an indication of how well the system worked without taking into account the ability of the user who may be providing the edge rules for a particular model. Not taking this into account would result in an inaccurate representation of its ability.

\subsection{Strengths and Weaknesses}
The resulting system successfully satisfied both the functional and non functional requirements in addition to providing insights into the possibilities of a hybrid technique for effective finite element meshing, something that was optimistic at the start of the project but highly desirable. The project was well managed with all of the objectives being delivered as per the initial time plan. Quality was also maintained throughout the project by the application of good software engineering practice. \\

\noindent
The modular architecture turned out to be the first great strength of the system allowing for a huge amount amount of potential extendibility in the future and simplifying the ease with which both of the methods could be integrated separately into the system. Although little focus has so far been given to the system's usability it could be developed and distributed as a public tool for experimentation with hybrid meshing with limited additional effort. Another highly flexible aspect is the system's ability to also accept any heuristic definition in terms of edges within a mesh structure. Theoretically this means the final system is also capable of using the same types of edge specifications for any type of FE analysis such as fluid flow or heat transfer given a corresponding rule set by which to mesh with. \\


\noindent
A downside of the current design is the need for the user to manually specify the edges by the user directly into the JSON input file which is both time consuming and prone to error despite the relatively small size of the models analysed in this dissertation. Comparing the size of these with those used in industry it is clear that this process is simply not practical for engineers conducting FE analysis. To change this better tools are required that will allow engineers to automatically generate edge specifications quickly, most likely through some GUI or a bespoke high level language capable of combining knowledge about the mesh structure and different types of edges to generate specific rules. Again this is beyond the scope of the project and would likely be a dissertation in its own right. \\


\noindent
Although the system had a strong subsystem and class level architecture many of its weaknesses could be attributed to needing to prioritise the ability to perform rapid prototyping over efficient implementation of the various algorithms and methods described in this dissertation. Much of this a consequence of overusing the functional programming capabilities within the C\# LINQ library. Widespread adoption of functional programming practices was stated as a desirable aspect of the final system implementation within the non-functional requirements so as to simply the design and reduce unnecessary state. This has largely been adhered to with  higher order and lambda functions widespread throughout the codebase. In the later stages of the project it became apparent however that in many cases reliance on these features resulted in reduced readability and performance for many of underlying algorithms described in this dissertation. 



% Overall the project met all its initial requirements laid out in both the objectives and its requirements.
% Sould have done test driven development to ease testing at the end



%in combining FEA and AI to produce and optimum FEM as demonstrated by the experiments I undertook. The method I developed resulted in data that was xx% more accurate than using a traditional stress based method. This is evidenced by the data provided in Appendix zzz of the report.



%